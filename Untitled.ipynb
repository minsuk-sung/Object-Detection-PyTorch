{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca9da06",
   "metadata": {},
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2adca",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Flags.py\" data-toc-modified-id=\"Flags.py-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Flags.py</a></span></li><li><span><a href=\"#checkpoint.py\" data-toc-modified-id=\"checkpoint.py-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>checkpoint.py</a></span></li><li><span><a href=\"#utils.py\" data-toc-modified-id=\"utils.py-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>utils.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#get_network\" data-toc-modified-id=\"get_network-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>get_network</a></span></li><li><span><a href=\"#get_optimizer\" data-toc-modified-id=\"get_optimizer-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>get_optimizer</a></span></li><li><span><a href=\"#transform_bbox\" data-toc-modified-id=\"transform_bbox-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>transform_bbox</a></span></li><li><span><a href=\"#SmoothedValue\" data-toc-modified-id=\"SmoothedValue-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>SmoothedValue</a></span></li><li><span><a href=\"#all_gather\" data-toc-modified-id=\"all_gather-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>all_gather</a></span></li><li><span><a href=\"#reduce_dict\" data-toc-modified-id=\"reduce_dict-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>reduce_dict</a></span></li><li><span><a href=\"#MetricLogger\" data-toc-modified-id=\"MetricLogger-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>MetricLogger</a></span></li><li><span><a href=\"#collate_fn\" data-toc-modified-id=\"collate_fn-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>collate_fn</a></span></li><li><span><a href=\"#warmup_lr_scheduler\" data-toc-modified-id=\"warmup_lr_scheduler-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>warmup_lr_scheduler</a></span></li><li><span><a href=\"#mkdir\" data-toc-modified-id=\"mkdir-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>mkdir</a></span></li><li><span><a href=\"#setup_for_distributed\" data-toc-modified-id=\"setup_for_distributed-3.11\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;</span>setup_for_distributed</a></span></li><li><span><a href=\"#is_dist_avail_and_initialized\" data-toc-modified-id=\"is_dist_avail_and_initialized-3.12\"><span class=\"toc-item-num\">3.12&nbsp;&nbsp;</span>is_dist_avail_and_initialized</a></span></li><li><span><a href=\"#get_world_size\" data-toc-modified-id=\"get_world_size-3.13\"><span class=\"toc-item-num\">3.13&nbsp;&nbsp;</span>get_world_size</a></span></li><li><span><a href=\"#get_rank\" data-toc-modified-id=\"get_rank-3.14\"><span class=\"toc-item-num\">3.14&nbsp;&nbsp;</span>get_rank</a></span></li><li><span><a href=\"#is_main_process\" data-toc-modified-id=\"is_main_process-3.15\"><span class=\"toc-item-num\">3.15&nbsp;&nbsp;</span>is_main_process</a></span></li><li><span><a href=\"#save_on_master\" data-toc-modified-id=\"save_on_master-3.16\"><span class=\"toc-item-num\">3.16&nbsp;&nbsp;</span>save_on_master</a></span></li><li><span><a href=\"#init_distributed_mode\" data-toc-modified-id=\"init_distributed_mode-3.17\"><span class=\"toc-item-num\">3.17&nbsp;&nbsp;</span>init_distributed_mode</a></span></li></ul></li><li><span><a href=\"#dataset.py\" data-toc-modified-id=\"dataset.py-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>dataset.py</a></span></li><li><span><a href=\"#engine.py\" data-toc-modified-id=\"engine.py-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>engine.py</a></span></li><li><span><a href=\"#train.py\" data-toc-modified-id=\"train.py-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>train.py</a></span></li><li><span><a href=\"#test.py\" data-toc-modified-id=\"test.py-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>test.py</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144ec31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:27.918916Z",
     "start_time": "2021-10-25T08:21:27.862801Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fire\n",
    "import gzip\n",
    "import yaml\n",
    "import glob\n",
    "import errno\n",
    "import random\n",
    "import shutil\n",
    "import platform\n",
    "import warnings\n",
    "import collections\n",
    "from psutil import virtual_memory\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea82945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:28.356943Z",
     "start_time": "2021-10-25T08:21:27.921170Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d5c2b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.032560Z",
     "start_time": "2021-10-25T08:21:28.359497Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Sampler, Dataset, DataLoader \n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tensorboardX import SummaryWriter\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45cb2a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.056458Z",
     "start_time": "2021-10-25T08:21:29.034416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current OS: Linux\n",
      "CUDA: True\n",
      "Python Version: 3.7.10\n",
      "torch Version: 1.8.2\n",
      "torchvision Version: 0.9.2\n"
     ]
    }
   ],
   "source": [
    "# 현재 OS 및 라이브러리 버전 체크 체크\n",
    "current_os = platform.system()\n",
    "print(f\"Current OS: {current_os}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "print(f\"torch Version: {torch.__version__}\")\n",
    "print(f\"torchvision Version: {torchvision.__version__}\")\n",
    "\n",
    "# 중요하지 않은 에러 무시\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 유니코드 깨짐현상 해결\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 나눔고딕 폰트 적용\n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff2158",
   "metadata": {},
   "source": [
    "## Flags.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed47c87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.074854Z",
     "start_time": "2021-10-25T08:21:29.057741Z"
    }
   },
   "outputs": [],
   "source": [
    "def dict_to_namedtuple(d):\n",
    "    \"\"\"\n",
    "    Convert dictionary to named tuple.\n",
    "    \"\"\"\n",
    "    FLAGSTuple = collections.namedtuple('FLAGS', sorted(d.keys()))\n",
    "\n",
    "    for k, v in d.items():\n",
    "        if k == 'PREFIX' or k == 'prefix':\n",
    "            v = os.path.join('./', v)\n",
    "        if type(v) is dict:\n",
    "            d[k] = dict_to_namedtuple(v)\n",
    "        elif type(v) is str:\n",
    "            try:\n",
    "                d[k] = eval(v)\n",
    "            except:\n",
    "                d[k] = v\n",
    "    nt = FLAGSTuple(**d)\n",
    "\n",
    "    return nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf011848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.089029Z",
     "start_time": "2021-10-25T08:21:29.076117Z"
    }
   },
   "outputs": [],
   "source": [
    "class Flags:\n",
    "    \"\"\"\n",
    "    Flags object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_file):\n",
    "        try:\n",
    "            with open(config_file, 'r') as f:\n",
    "                d = yaml.safe_load(f)\n",
    "        except:\n",
    "            d = config_file\n",
    "\n",
    "        self.flags = dict_to_namedtuple(d)\n",
    "\n",
    "    def get(self):\n",
    "        return self.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe85ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.114204Z",
     "start_time": "2021-10-25T08:21:29.090297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAGS(BATCH_SIZE=1, CHECKPOINT='', DATA=FLAGS(TRAIN_ANN_PATH='/DATASET/COCO2017/annotations/instances_train2017.json', TRAIN_IMG_PATH='/DATASET/COCO2017/images/train2017', VALID_ANN_PATH='/DATASET/COCO2017/annotations/instances_val2017.json', VALID_IMG_PATH='/DATASET/COCO2017/images/val2017'), DEVICE='cuda', DROPOUT_RATE=0.1, EARLY_STOPPING_EPOCH=5, LR_SCHEDULER=FLAGS(GAMMA=0.1, STEP_SIZE=5), NETWORK=FLAGS(NAME='Faster R-CNN', PRETRAINED=False), NUM_EPOCHS=1, NUM_WORKERS=0, OPTIMIZER=FLAGS(LR=0.0001, TYPE='Adam', WEIGHT_DECAY_RATE=0.01), PREFIX='././log/FASTER-RCNN', PRINT_EPOCHS=1, PRINT_FREQ=100, SEED=42, SHUFFLE=False, experiment=FLAGS(vis_input='samples/fake.jpg', vis_output='./results'), test_checkpoint='./log/VGG_NP/checkpoints/0020.pth')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = \"configs/faster-rcnn.yaml\"\n",
    "cfg = Flags(config_file).get()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de373cea",
   "metadata": {},
   "source": [
    "## checkpoint.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebf30db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.123714Z",
     "start_time": "2021-10-25T08:21:29.116411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1656884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.137575Z",
     "start_time": "2021-10-25T08:21:29.125553Z"
    }
   },
   "outputs": [],
   "source": [
    "default_checkpoint = {\n",
    "    \"epoch\": 0,\n",
    "\n",
    "    # train\n",
    "    \"train_loss\": [],\n",
    "    \"train_loss_classifier\": [],\n",
    "    \"train_loss_box_reg\": [],\n",
    "    \"train_loss_objectness\": [],\n",
    "    \"train_loss_rpn_box_reg\": [],\n",
    "\n",
    "    # valid\n",
    "    \"valid_loss\": [],\n",
    "    \"valid_loss_classifier\": [],\n",
    "    \"valid_loss_box_reg\": [],\n",
    "    \"valid_loss_objectness\": [],\n",
    "    \"valid_loss_rpn_box_reg\": [],\n",
    "\n",
    "    \"lr\": [], \n",
    "    \"model\": {},\n",
    "    \"configs\":{},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70142fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.152646Z",
     "start_time": "2021-10-25T08:21:29.139416Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint, dir=\"./checkpoints\", prefix=\"\"):\n",
    "    # Padded to 4 digits because of lexical sorting of numbers.\n",
    "    # e.g. 0009.pth\n",
    "    filename = \"{num:0>4}.pth\".format(num=checkpoint[\"epoch\"])\n",
    "    if not os.path.exists(os.path.join(prefix, dir)):\n",
    "        os.makedirs(os.path.join(prefix, dir))\n",
    "    torch.save(checkpoint, os.path.join(prefix, dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37aa15e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.175074Z",
     "start_time": "2021-10-25T08:21:29.154496Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(path, cuda=use_cuda):\n",
    "    if cuda:\n",
    "        return torch.load(path)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        return torch.load(path, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365d7bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.189436Z",
     "start_time": "2021-10-25T08:21:29.177291Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_tensorboard(name=\"\", base_dir=\"./tensorboard\"):\n",
    "    return SummaryWriter(os.path.join(name, base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aea7508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.205007Z",
     "start_time": "2021-10-25T08:21:29.191532Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_tensorboard(\n",
    "    writer,\n",
    "    epoch,\n",
    "    train_loss,\n",
    "    train_accuracy,\n",
    "    train_precision,\n",
    "    train_recall,\n",
    "    valid_loss,\n",
    "    valid_accuracy,\n",
    "    valid_precision,\n",
    "    valid_recall,\n",
    "    model,\n",
    "):\n",
    "    writer.add_scalar(\"train_loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"train_accuracy\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"train_precision\", train_precision, epoch)\n",
    "    writer.add_scalar(\"train_recall\", train_recall, epoch)\n",
    "    writer.add_scalar(\"valid_loss\", valid_loss, epoch)\n",
    "    writer.add_scalar(\"valid_accuracy\", valid_accuracy, epoch)\n",
    "    writer.add_scalar(\"valid_precision\", valid_precision, epoch)\n",
    "    writer.add_scalar(\"valid_recall\", valid_recall, epoch)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(\n",
    "            \"{}\".format(name), param.detach().cpu().numpy(), epoch\n",
    "        )\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(\n",
    "                \"{}/grad\".format(name), param.grad.detach().cpu().numpy(), epoch\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd744ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.218924Z",
     "start_time": "2021-10-25T08:21:29.206341Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = (\n",
    "    load_checkpoint(cfg.CHECKPOINT, cuda=is_cuda)\n",
    "    if cfg.CHECKPOINT != \"\"\n",
    "    else default_checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad8030fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.235764Z",
     "start_time": "2021-10-25T08:21:29.220615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 0,\n",
       " 'train_loss': [],\n",
       " 'train_loss_classifier': [],\n",
       " 'train_loss_box_reg': [],\n",
       " 'train_loss_objectness': [],\n",
       " 'train_loss_rpn_box_reg': [],\n",
       " 'valid_loss': [],\n",
       " 'valid_loss_classifier': [],\n",
       " 'valid_loss_box_reg': [],\n",
       " 'valid_loss_objectness': [],\n",
       " 'valid_loss_rpn_box_reg': [],\n",
       " 'lr': [],\n",
       " 'model': {},\n",
       " 'configs': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7fe3c",
   "metadata": {},
   "source": [
    "## utils.py\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c505a",
   "metadata": {},
   "source": [
    "### get_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e59d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:29.249183Z",
     "start_time": "2021-10-25T08:21:29.237591Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_network(\n",
    "    cfg\n",
    "):\n",
    "    model = None\n",
    "    if cfg.NETWORK.NAME == 'Faster R-CNN':\n",
    "        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "            pretrained=cfg.NETWORK.PRETRAINED\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return model.to(cfg.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df107bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:31.993469Z",
     "start_time": "2021-10-25T08:21:29.250878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_network(cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cffb098",
   "metadata": {},
   "source": [
    "### get_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc5c62cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:31.997857Z",
     "start_time": "2021-10-25T08:21:31.994930Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(\n",
    "    params,\n",
    "    cfg\n",
    "):\n",
    "    if cfg.OPTIMIZER.TYPE == \"Adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            params,\n",
    "             lr=cfg.OPTIMIZER.LR, \n",
    "             weight_decay=cfg.OPTIMIZER.WEIGHT_DECAY_RATE\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f64612e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:49:13.824052Z",
     "start_time": "2021-10-25T08:49:13.817452Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(params_to_optimise, cfg)\n",
    "optimizer_state = checkpoint.get(\"optimizer\")\n",
    "if optimizer_state:\n",
    "    optimizer.load_state_dict(optimizer_state)\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group[\"initial_lr\"] = cfg.OPTIMIZER.LR\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=cfg.LR_SCHEDULER.STEP_SIZE,\n",
    "    gamma=cfg.LR_SCHEDULER.GAMMA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "140da1fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.044896Z",
     "start_time": "2021-10-25T08:21:31.999225Z"
    }
   },
   "outputs": [],
   "source": [
    "model_state = checkpoint.get(\"model\")\n",
    "\n",
    "if model_state:\n",
    "    model.load_state_dict(model_state)\n",
    "    print(\n",
    "        \"\\033[31m[+] Checkpoint\\033[00m\\n\",\n",
    "        \"Resuming from epoch : {}\\n\".format(checkpoint[\"epoch\"]),\n",
    "        \"Train Accuracy : {:.5f}\\n\".format(\n",
    "            checkpoint[\"train_accuracy\"][-1]),\n",
    "        \"Train Loss : {:.5f}\\n\".format(checkpoint[\"train_losses\"][-1]),\n",
    "        \"Valid Accuracy : {:.5f}\\n\".format(\n",
    "            checkpoint[\"valid_accuracy\"][-1]),\n",
    "        \"Valid Loss : {:.5f}\\n\".format(checkpoint[\"valid_losses\"][-1]),\n",
    "    )\n",
    "\n",
    "params_to_optimise = [\n",
    "    param for param in model.parameters() if param.requires_grad\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93585b",
   "metadata": {},
   "source": [
    "### transform_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1745f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.058625Z",
     "start_time": "2021-10-25T08:21:32.046320Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_bbox(bbox):\n",
    "    \"\"\"\n",
    "    COCO Bounding box: (x-top left, y-top left, width, height)\n",
    "    Pascal VOC Bounding box :(x-top left, y-top left,x-bottom right, y-bottom right)\n",
    "    \"\"\"\n",
    "    xmin = bbox[0]\n",
    "    ymin = bbox[1]\n",
    "    xmax = bbox[0]+bbox[2]\n",
    "    ymax = bbox[1]+bbox[3]\n",
    "    \n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d0ecd",
   "metadata": {},
   "source": [
    "### SmoothedValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c569401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.073691Z",
     "start_time": "2021-10-25T08:21:32.060169Z"
    }
   },
   "outputs": [],
   "source": [
    "class SmoothedValue(object):\n",
    "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
    "    window or the global series average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=20, fmt=None):\n",
    "        if fmt is None:\n",
    "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.total],\n",
    "                         dtype=torch.float64, device='cuda')\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.total = t[1]\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return max(self.deque)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.deque[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg,\n",
    "            max=self.max,\n",
    "            value=self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a65fc",
   "metadata": {},
   "source": [
    "### all_gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5b3d981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.093771Z",
     "start_time": "2021-10-25T08:21:32.075172Z"
    }
   },
   "outputs": [],
   "source": [
    "def all_gather(data):\n",
    "    \"\"\"\n",
    "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
    "    Args:\n",
    "        data: any picklable object\n",
    "    Returns:\n",
    "        list[data]: list of data gathered from each rank\n",
    "    \"\"\"\n",
    "    world_size = get_world_size()\n",
    "    if world_size == 1:\n",
    "        return [data]\n",
    "    data_list = [None] * world_size\n",
    "    dist.all_gather_object(data_list, data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72189645",
   "metadata": {},
   "source": [
    "### reduce_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c1a15d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.109130Z",
     "start_time": "2021-10-25T08:21:32.098813Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_dict(input_dict, average=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dict (dict): all the values will be reduced\n",
    "        average (bool): whether to do average or sum\n",
    "    Reduce the values in the dictionary from all processes so that all processes\n",
    "    have the averaged results. Returns a dict with the same fields as\n",
    "    input_dict, after reduction.\n",
    "    \"\"\"\n",
    "    world_size = get_world_size()\n",
    "    if world_size < 2:\n",
    "        return input_dict\n",
    "    with torch.no_grad():\n",
    "        names = []\n",
    "        values = []\n",
    "        # sort the keys so that they are consistent across processes\n",
    "        for k in sorted(input_dict.keys()):\n",
    "            names.append(k)\n",
    "            values.append(input_dict[k])\n",
    "        values = torch.stack(values, dim=0)\n",
    "        dist.all_reduce(values)\n",
    "        if average:\n",
    "            values /= world_size\n",
    "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
    "    return reduced_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc2229",
   "metadata": {},
   "source": [
    "### MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8217a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.128727Z",
     "start_time": "2021-10-25T08:21:32.110808Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricLogger(object):\n",
    "    def __init__(self, delimiter=\"\\t\"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            assert isinstance(v, (float, int))\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, attr))\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(\n",
    "                \"\\033[32m{}\\033[00m: {}\".format(name, str(meter))\n",
    "            )\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        if not header:\n",
    "            header = ''\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
    "        if torch.cuda.is_available():\n",
    "            log_msg = self.delimiter.join([\n",
    "                '\\033[33m[{current_time}]\\033[00m ',\n",
    "                header,\n",
    "                '({0' + space_fmt + '}/{1})',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}',\n",
    "                'max mem: {memory:.0f}'\n",
    "            ])\n",
    "        else:\n",
    "            log_msg = self.delimiter.join([\n",
    "                '\\033[33m[{current_time}]\\033[00m ',\n",
    "                header,\n",
    "                '({0' + space_fmt + '}/{1})',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}'\n",
    "            ])\n",
    "        MB = 1024.0 * 1024.0\n",
    "        for obj in iterable:\n",
    "            data_time.update(time.time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time.time() - end)\n",
    "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
    "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                if torch.cuda.is_available():\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        current_time = str(datetime.datetime.now())[:-7],\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time),\n",
    "                        memory=torch.cuda.max_memory_allocated() / MB))\n",
    "                else:\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        current_time = str(datetime.datetime.now())[:-7],\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time)))\n",
    "            i += 1\n",
    "            end = time.time()\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('{} Total time: {} ({:.4f} s / it)'.format(\n",
    "            header, total_time_str, total_time / len(iterable)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "070bb7bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:47:49.496383Z",
     "start_time": "2021-10-25T08:47:49.490372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(__main__.SmoothedValue, {})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetricLogger(delimiter=\"  \").meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8ce21",
   "metadata": {},
   "source": [
    "### collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "785d2496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.147887Z",
     "start_time": "2021-10-25T08:21:32.130613Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa4114",
   "metadata": {},
   "source": [
    "### warmup_lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9455421a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.162004Z",
     "start_time": "2021-10-25T08:21:32.149880Z"
    }
   },
   "outputs": [],
   "source": [
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7decc8",
   "metadata": {},
   "source": [
    "### mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "779bb10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.176008Z",
     "start_time": "2021-10-25T08:21:32.164263Z"
    }
   },
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6dd35",
   "metadata": {},
   "source": [
    "### setup_for_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5dfc607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.190649Z",
     "start_time": "2021-10-25T08:21:32.178350Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_for_distributed(is_master):\n",
    "    \"\"\"\n",
    "    This function disables printing when not in master process\n",
    "    \"\"\"\n",
    "    import builtins as __builtin__\n",
    "    builtin_print = __builtin__.print\n",
    "\n",
    "    def print(*args, **kwargs):\n",
    "        force = kwargs.pop('force', False)\n",
    "        if is_master or force:\n",
    "            builtin_print(*args, **kwargs)\n",
    "\n",
    "    __builtin__.print = print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45229c6",
   "metadata": {},
   "source": [
    "### is_dist_avail_and_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e6d321f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.209997Z",
     "start_time": "2021-10-25T08:21:32.192850Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189db23f",
   "metadata": {},
   "source": [
    "### get_world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b27d239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.224628Z",
     "start_time": "2021-10-25T08:21:32.212418Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_world_size():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba202a",
   "metadata": {},
   "source": [
    "### get_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f060ea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.239015Z",
     "start_time": "2021-10-25T08:21:32.227240Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rank():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 0\n",
    "    return dist.get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56484e",
   "metadata": {},
   "source": [
    "### is_main_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3368697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.253430Z",
     "start_time": "2021-10-25T08:21:32.241470Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_main_process():\n",
    "    return get_rank() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101adfe",
   "metadata": {},
   "source": [
    "### save_on_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df8587ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.268141Z",
     "start_time": "2021-10-25T08:21:32.255912Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_on_master(*args, **kwargs):\n",
    "    if is_main_process():\n",
    "        torch.save(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54517bd8",
   "metadata": {},
   "source": [
    "### init_distributed_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94c87b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:21:32.282887Z",
     "start_time": "2021-10-25T08:21:32.270491Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_distributed_mode(args):\n",
    "    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "        args.world_size = int(os.environ['WORLD_SIZE'])\n",
    "        args.gpu = int(os.environ['LOCAL_RANK'])\n",
    "    elif 'SLURM_PROCID' in os.environ:\n",
    "        args.rank = int(os.environ['SLURM_PROCID'])\n",
    "        args.gpu = args.rank % torch.cuda.device_count()\n",
    "    else:\n",
    "        print('Not using distributed mode')\n",
    "        args.distributed = False\n",
    "        return\n",
    "\n",
    "    args.distributed = True\n",
    "\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    args.dist_backend = 'nccl'\n",
    "    print('| distributed init (rank {}): {}'.format(\n",
    "        args.rank, args.dist_url), flush=True)\n",
    "    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                         world_size=args.world_size, rank=args.rank)\n",
    "    torch.distributed.barrier()\n",
    "    setup_for_distributed(args.rank == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c26dc7",
   "metadata": {},
   "source": [
    "## dataset.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01bd03df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:25:39.786546Z",
     "start_time": "2021-10-25T08:25:39.777724Z"
    }
   },
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00bc16be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T07:38:18.663929Z",
     "start_time": "2021-10-28T07:38:18.645889Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomCOCODataset(Dataset):\n",
    "    def __init__(self, img_path=None, ann_path=None, transforms=None):\n",
    "\n",
    "        if not img_path or not ann_path:\n",
    "            raise Exception('You must check your image or annotations path')\n",
    "\n",
    "        self.img_path = img_path\n",
    "        self.ann_path = ann_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.imgs = sorted(glob.glob(os.path.join(self.img_path, '*.jpg')))\n",
    "        self.anns = COCO(self.ann_path)\n",
    "        self.anns_ids = self.anns.getCatIds()\n",
    "        self.anns_iscrowd = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        #########\n",
    "        # Image #\n",
    "        #########\n",
    "        imgId = int(self.imgs[idx].split('/')[-1].split('.')[0])\n",
    "        img = Image.open(self.imgs[idx]).convert(\"RGB\")\n",
    "\n",
    "        # This is RBG data\n",
    "        img_origin = cv2.imread(self.imgs[idx])\n",
    "        img_origin = cv2.cvtColor(img_origin, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        ################################################################################\n",
    "        # Target                                                                       #\n",
    "        # ['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'] #\n",
    "        ################################################################################\n",
    "        annsId = self.anns.getAnnIds(\n",
    "            imgIds=imgId,\n",
    "            catIds=self.anns_ids,\n",
    "            iscrowd=self.anns_iscrowd\n",
    "        )\n",
    "\n",
    "        anns = self.anns.loadAnns(annsId)\n",
    "        print(anns)\n",
    "\n",
    "        targets = {}\n",
    "        targets[\"boxes\"] = torch.tensor(\n",
    "            [utils.transform_bbox(ann['bbox']) for ann in anns])\n",
    "        targets[\"labels\"] = torch.tensor([ann['category_id'] for ann in anns])\n",
    "        targets[\"image_id\"] = torch.tensor(anns[0]['image_id'])\n",
    "        targets[\"area\"] = torch.tensor([ann['area'] for ann in anns])\n",
    "        targets[\"iscrowd\"] = torch.tensor([ann['iscrowd'] for ann in anns])\n",
    "\n",
    "        #############\n",
    "        # Transform #\n",
    "        #############\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9b3a06d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T07:38:19.214656Z",
     "start_time": "2021-10-28T07:38:19.208922Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomCOCOSampler(Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "        self.existing_ann = {}\n",
    "        self.missing_ann = {}\n",
    "        \n",
    "        imgIds = {idx:int(path.split('/')[-1].split('.')[0])\n",
    "                  for idx, path in enumerate(self.data_source.imgs)}\n",
    "\n",
    "        for idx, imgId in imgIds.items():\n",
    "            annsId = self.data_source.anns.getAnnIds(\n",
    "                imgIds=imgId,\n",
    "                catIds=self.data_source.anns.getCatIds(),\n",
    "                iscrowd=False,\n",
    "            )\n",
    "\n",
    "            anns = self.data_source.anns.loadAnns(annsId)\n",
    "\n",
    "            if len(anns) <= 0:\n",
    "                self.missing_ann[idx] = imgId\n",
    "            else:\n",
    "                self.existing_ann[idx] = imgId\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(list(self.existing_ann.keys()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a81ef929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T07:38:19.630009Z",
     "start_time": "2021-10-28T07:38:19.622794Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_coco_dataset_dataloader(cfg):\n",
    "\n",
    "    # DATASET\n",
    "    dataset_train = CustomCOCODataset(\n",
    "        img_path=cfg.DATA.TRAIN_IMG_PATH,\n",
    "        ann_path=cfg.DATA.TRAIN_ANN_PATH,\n",
    "        transforms=T.Compose([\n",
    "            T.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "\n",
    "    dataset_valid = CustomCOCODataset(\n",
    "        img_path=cfg.DATA.VALID_IMG_PATH,\n",
    "        ann_path=cfg.DATA.VALID_ANN_PATH,\n",
    "        transforms=T.Compose([\n",
    "            T.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "\n",
    "    # SAMPLER\n",
    "    sampler_train = CustomCOCOSampler(\n",
    "        data_source=dataset_train\n",
    "    )\n",
    "\n",
    "    sampler_valid = CustomCOCOSampler(\n",
    "        data_source=dataset_valid\n",
    "    )\n",
    "\n",
    "    # DATALOADER\n",
    "    dataloader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=cfg.BATCH_SIZE,\n",
    "        shuffle=cfg.SHUFFLE, \n",
    "        sampler=sampler_train,\n",
    "        num_workers=cfg.NUM_WORKERS,  # default: 0\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    dataloader_valid = torch.utils.data.DataLoader(\n",
    "        dataset_valid,\n",
    "        batch_size=1,  # default: 1 for validation\n",
    "        shuffle=cfg.SHUFFLE, \n",
    "        sampler=sampler_valid,\n",
    "        num_workers=cfg.NUM_WORKERS,  # default: 0\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    return dataset_train, dataset_valid, dataloader_train, dataloader_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fbc21086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T07:38:41.322796Z",
     "start_time": "2021-10-28T07:38:20.145897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=17.21s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.44s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_valid, dataloader_train, dataloader_valid = get_coco_dataset_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cc5bb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T07:38:41.347783Z",
     "start_time": "2021-10-28T07:38:41.324581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'segmentation': [[500.49, 473.53, 599.73, 419.6, 612.67, 375.37, 608.36, 354.88, 528.54, 269.66, 457.35, 201.71, 420.67, 187.69, 389.39, 192.0, 19.42, 360.27, 1.08, 389.39, 2.16, 427.15, 20.49, 473.53]], 'area': 120057.13925, 'iscrowd': 0, 'image_id': 9, 'bbox': [1.08, 187.69, 611.59, 285.84], 'category_id': 51, 'id': 1038967}, {'segmentation': [[357.03, 69.03, 311.73, 15.1, 550.11, 4.31, 631.01, 62.56, 629.93, 88.45, 595.42, 185.53, 513.44, 230.83, 488.63, 232.99, 437.93, 190.92, 429.3, 189.84, 434.7, 148.85, 410.97, 121.89, 359.19, 74.43, 358.11, 65.8]], 'area': 44434.751099999994, 'iscrowd': 0, 'image_id': 9, 'bbox': [311.73, 4.31, 319.28, 228.68], 'category_id': 51, 'id': 1039564}, {'segmentation': [[249.6, 348.99, 267.67, 311.72, 291.39, 294.78, 304.94, 294.78, 326.4, 283.48, 345.6, 273.32, 368.19, 269.93, 385.13, 268.8, 388.52, 257.51, 393.04, 250.73, 407.72, 240.56, 425.79, 230.4, 441.6, 229.27, 447.25, 237.18, 447.25, 256.38, 456.28, 254.12, 475.48, 263.15, 486.78, 271.06, 495.81, 264.28, 498.07, 257.51, 500.33, 255.25, 507.11, 259.76, 513.88, 266.54, 513.88, 273.32, 513.88, 276.71, 526.31, 276.71, 526.31, 286.87, 519.53, 291.39, 519.53, 297.04, 524.05, 306.07, 525.18, 315.11, 529.69, 329.79, 529.69, 337.69, 530.82, 348.99, 536.47, 339.95, 545.51, 350.12, 555.67, 360.28, 557.93, 380.61, 561.32, 394.16, 565.84, 413.36, 522.92, 441.6, 469.84, 468.71, 455.15, 474.35, 307.2, 474.35, 316.24, 464.19, 330.92, 438.21, 325.27, 399.81, 310.59, 378.35, 301.55, 371.58, 252.99, 350.12]], 'area': 49577.94434999999, 'iscrowd': 0, 'image_id': 9, 'bbox': [249.6, 229.27, 316.24, 245.08], 'category_id': 56, 'id': 1058555}, {'segmentation': [[434.48, 152.33, 433.51, 184.93, 425.44, 189.45, 376.7, 195.58, 266.94, 248.53, 179.78, 290.17, 51.62, 346.66, 16.43, 366.68, 1.9, 388.63, 0.0, 377.33, 0.0, 357.64, 0.0, 294.04, 22.56, 294.37, 56.14, 300.82, 83.58, 300.82, 109.08, 289.2, 175.26, 263.38, 216.9, 243.36, 326.34, 197.52, 387.03, 172.34, 381.54, 162.33, 380.89, 147.16, 380.89, 140.06, 370.89, 102.29, 330.86, 61.94, 318.91, 48.38, 298.57, 47.41, 287.28, 37.73, 259.51, 33.85, 240.14, 32.56, 240.14, 28.36, 247.57, 24.17, 271.46, 15.13, 282.11, 13.51, 296.96, 18.68, 336.34, 55.48, 391.55, 106.81, 432.87, 147.16], [62.46, 97.21, 130.25, 69.77, 161.25, 59.12, 183.52, 52.02, 180.94, 59.12, 170.93, 78.17, 170.28, 90.76, 157.05, 95.92, 130.25, 120.78, 119.92, 129.49, 102.17, 115.29, 64.72, 119.81, 0.0, 137.89, 0.0, 120.13, 0.0, 117.87]], 'area': 24292.781700000007, 'iscrowd': 0, 'image_id': 9, 'bbox': [0.0, 13.51, 434.48, 375.12], 'category_id': 51, 'id': 1534147}, {'segmentation': [[376.2, 61.55, 391.86, 46.35, 424.57, 40.36, 441.62, 43.59, 448.07, 50.04, 451.75, 63.86, 448.07, 68.93, 439.31, 70.31, 425.49, 73.53, 412.59, 75.38, 402.92, 84.13, 387.71, 86.89, 380.8, 70.77]], 'area': 2239.2924, 'iscrowd': 0, 'image_id': 9, 'bbox': [376.2, 40.36, 75.55, 46.53], 'category_id': 55, 'id': 1913551}, {'segmentation': [[473.92, 85.64, 469.58, 83.47, 465.78, 78.04, 466.87, 72.08, 472.84, 59.59, 478.26, 47.11, 496.71, 38.97, 514.62, 40.6, 521.13, 49.28, 523.85, 55.25, 520.05, 63.94, 501.06, 72.62, 482.6, 82.93]], 'area': 1658.8913000000007, 'iscrowd': 0, 'image_id': 9, 'bbox': [465.78, 38.97, 58.07, 46.67], 'category_id': 55, 'id': 1913746}, {'segmentation': [[385.7, 85.85, 407.12, 80.58, 419.31, 79.26, 426.56, 77.94, 435.45, 74.65, 442.7, 73.66, 449.95, 73.99, 456.87, 77.94, 463.46, 83.87, 467.74, 92.77, 469.39, 104.63, 469.72, 117.15, 469.39, 135.27, 468.73, 141.86, 466.09, 144.17, 449.29, 141.53, 437.1, 136.92, 430.18, 129.67]], 'area': 3609.3030499999995, 'iscrowd': 0, 'image_id': 9, 'bbox': [385.7, 73.66, 84.02, 70.51], 'category_id': 55, 'id': 1913856}, {'segmentation': [[458.81, 24.94, 437.61, 4.99, 391.48, 2.49, 364.05, 56.1, 377.77, 73.56, 377.77, 56.1, 392.73, 41.14, 403.95, 41.14, 420.16, 39.9, 435.12, 42.39, 442.6, 46.13, 455.06, 31.17]], 'area': 2975.276, 'iscrowd': 0, 'image_id': 9, 'bbox': [364.05, 2.49, 94.76, 71.07], 'category_id': 55, 'id': 1914001}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0078, 0.0039, 0.0000,  ..., 0.5255, 0.5255, 0.5137],\n",
       "          [0.0196, 0.0118, 0.0039,  ..., 0.5373, 0.5294, 0.5137],\n",
       "          [0.0039, 0.0000, 0.0000,  ..., 0.5412, 0.5333, 0.5176],\n",
       "          ...,\n",
       "          [0.0118, 0.0235, 0.0275,  ..., 0.0000, 0.0157, 0.0392],\n",
       "          [0.0196, 0.0196, 0.0275,  ..., 0.0510, 0.0235, 0.0118],\n",
       "          [0.0157, 0.0196, 0.0275,  ..., 0.0039, 0.0078, 0.0078]],\n",
       " \n",
       "         [[0.0941, 0.0902, 0.0863,  ..., 0.6706, 0.6706, 0.6588],\n",
       "          [0.0980, 0.0902, 0.0863,  ..., 0.6824, 0.6745, 0.6588],\n",
       "          [0.0824, 0.0784, 0.0745,  ..., 0.6863, 0.6784, 0.6627],\n",
       "          ...,\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0431, 0.0392, 0.0157],\n",
       "          [0.0000, 0.0000, 0.0118,  ..., 0.0314, 0.0078, 0.0078],\n",
       "          [0.0000, 0.0000, 0.0118,  ..., 0.0118, 0.0118, 0.0196]],\n",
       " \n",
       "         [[0.4275, 0.4275, 0.4235,  ..., 0.7725, 0.7725, 0.7647],\n",
       "          [0.4392, 0.4392, 0.4353,  ..., 0.7843, 0.7765, 0.7608],\n",
       "          [0.4314, 0.4275, 0.4353,  ..., 0.7882, 0.7804, 0.7647],\n",
       "          ...,\n",
       "          [0.0157, 0.0196, 0.0196,  ..., 0.1451, 0.1412, 0.1255],\n",
       "          [0.0235, 0.0157, 0.0157,  ..., 0.1490, 0.0980, 0.0784],\n",
       "          [0.0196, 0.0157, 0.0078,  ..., 0.1020, 0.0902, 0.0784]]]),\n",
       " {'boxes': tensor([[  1.0800, 187.6900, 612.6700, 473.5300],\n",
       "          [311.7300,   4.3100, 631.0100, 232.9900],\n",
       "          [249.6000, 229.2700, 565.8400, 474.3500],\n",
       "          [  0.0000,  13.5100, 434.4800, 388.6300],\n",
       "          [376.2000,  40.3600, 451.7500,  86.8900],\n",
       "          [465.7800,  38.9700, 523.8500,  85.6400],\n",
       "          [385.7000,  73.6600, 469.7200, 144.1700],\n",
       "          [364.0500,   2.4900, 458.8100,  73.5600]]),\n",
       "  'labels': tensor([51, 51, 56, 51, 55, 55, 55, 55]),\n",
       "  'image_id': tensor([1038967, 1039564, 1058555, 1534147, 1913551, 1913746, 1913856, 1914001]),\n",
       "  'area': tensor([120057.1406,  44434.7500,  49577.9453,  24292.7812,   2239.2925,\n",
       "            1658.8914,   3609.3030,   2975.2759]),\n",
       "  'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0])})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c915ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb196462",
   "metadata": {},
   "source": [
    "## engine.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7becc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12ca479b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:28:01.943974Z",
     "start_time": "2021-10-25T08:28:01.939071Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b89f8dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:52:06.874697Z",
     "start_time": "2021-10-25T08:52:06.859955Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(cfg, model, optimizer, data_loader, epoch):\n",
    "\n",
    "    # now = str(re.sub('[^0-9]', '', str(datetime.datetime.now())))\n",
    "\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = '\\033[31mEpoch: {}\\033[00m'.format(epoch)\n",
    "\n",
    "    lr_scheduler = None\n",
    "\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, cfg.PRINT_FREQ, header):\n",
    "        images = list(image.to(cfg.DEVICE) for image in images)\n",
    "        targets = [{k: v.to(cfg.DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "        break\n",
    "\n",
    "    return metric_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c6ade9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:52:07.323879Z",
     "start_time": "2021-10-25T08:52:07.316628Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_iou_types(model):\n",
    "    model_without_ddp = model\n",
    "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model_without_ddp = model.module\n",
    "    iou_types = [\"bbox\"]\n",
    "    if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
    "        iou_types.append(\"segm\")\n",
    "    if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
    "        iou_types.append(\"keypoints\")\n",
    "    return iou_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "163d87d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:52:07.566709Z",
     "start_time": "2021-10-25T08:52:07.557862Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device):\n",
    "    n_threads = torch.get_num_threads()\n",
    "    # FIXME remove this and make paste_masks_in_image run on the GPU\n",
    "    torch.set_num_threads(1)\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "\n",
    "    coco = get_coco_api_from_dataset(data_loader.dataset)\n",
    "    iou_types = _get_iou_types(model)\n",
    "    coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
    "        images = list(img.to(device) for img in images)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        model_time = time.time()\n",
    "        outputs = model(images)\n",
    "\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        model_time = time.time() - model_time\n",
    "\n",
    "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
    "        evaluator_time = time.time()\n",
    "        coco_evaluator.update(res)\n",
    "        evaluator_time = time.time() - evaluator_time\n",
    "        metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
    "\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    coco_evaluator.synchronize_between_processes()\n",
    "\n",
    "    # accumulate predictions from all images\n",
    "    coco_evaluator.accumulate()\n",
    "    coco_evaluator.summarize()\n",
    "    torch.set_num_threads(n_threads)\n",
    "    return coco_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f3b5a99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:52:07.792991Z",
     "start_time": "2021-10-25T08:52:07.790039Z"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65c55595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:52:45.125439Z",
     "start_time": "2021-10-25T08:52:44.963294Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    metric_logger = train_one_epoch(cfg, model, optimizer, dataloader_train, epoch)\n",
    "    lr_scheduler.step()\n",
    "#     evaluate(model, dataloader_valid, device=cfg.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4f7fbfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:56:20.747926Z",
     "start_time": "2021-10-25T08:56:20.741231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(utils.SmoothedValue,\n",
       "            {'lr': <utils.SmoothedValue at 0x7f8e120626d0>,\n",
       "             'loss': <utils.SmoothedValue at 0x7f8e11fbcb90>,\n",
       "             'loss_classifier': <utils.SmoothedValue at 0x7f8e11fbc550>,\n",
       "             'loss_box_reg': <utils.SmoothedValue at 0x7f8e11fbcfd0>,\n",
       "             'loss_objectness': <utils.SmoothedValue at 0x7f8e11fbcc10>,\n",
       "             'loss_rpn_box_reg': <utils.SmoothedValue at 0x7f8e11fbc450>})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_logger.meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9fa7d8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:56:22.745199Z",
     "start_time": "2021-10-25T08:56:22.739604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.999e-07"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_logger.meters['lr'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29c8c1f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T08:57:04.888049Z",
     "start_time": "2021-10-25T08:57:04.883464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0176215171813965"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_logger.meters['loss'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e24a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91fc144d",
   "metadata": {},
   "source": [
    "## train.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99464efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c2dad59",
   "metadata": {},
   "source": [
    "## test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a934ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364d5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8215e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d234632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7e05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817dae28",
   "metadata": {},
   "source": [
    "## Reference\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6115a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
